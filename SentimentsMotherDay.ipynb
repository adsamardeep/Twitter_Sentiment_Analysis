{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "SentimentsMotherDay.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adsamardeep/Twitter_Sentiment_Analysis/blob/master/SentimentsMotherDay.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCSGIqOhTElc",
        "colab_type": "code",
        "outputId": "e5dc7b47-bfd0-4617-9b89-7eba0a1d851f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import nltk\n",
        "import pandas as pd\n",
        "#from emoticons import EmoticonDetector\n",
        "import re as regex\n",
        "import numpy as np\n",
        "#import plotly\n",
        "#from plotly import graph_objs\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "#plotly.offline.init_notebook_mode()\n",
        "\n",
        "import seaborn as sns\n",
        "#import plotly\n",
        "#import cufflinks as cf\n",
        "import re\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuEgR9x_TEmE",
        "colab_type": "text"
      },
      "source": [
        "# Import the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydopSRyWTEmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv('Train.csv')\n",
        "test_data = pd.read_csv('Test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7o7ZwpXTEmd",
        "colab_type": "code",
        "outputId": "55795eca-47ec-4a5d-eb9d-51a64d5b7054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original_text</th>\n",
              "      <th>lang</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>original_author</th>\n",
              "      <th>sentiment_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.245025e+18</td>\n",
              "      <td>Happy #MothersDay to all you amazing mothers o...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>BeenXXPired</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.245759e+18</td>\n",
              "      <td>Happy Mothers Day Mum - I'm sorry I can't be t...</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>FestiveFeeling</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.246087e+18</td>\n",
              "      <td>Happy mothers day To all This doing a mothers ...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>KrisAllenSak</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.244803e+18</td>\n",
              "      <td>Happy mothers day to this beautiful woman...ro...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>Queenuchee</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.244876e+18</td>\n",
              "      <td>Remembering the 3 most amazing ladies who made...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>brittan17446794</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  ... sentiment_class\n",
              "0  1.245025e+18  ...               0\n",
              "1  1.245759e+18  ...               0\n",
              "2  1.246087e+18  ...              -1\n",
              "3  1.244803e+18  ...               0\n",
              "4  1.244876e+18  ...              -1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRVXLYwcTEmy",
        "colab_type": "code",
        "outputId": "e3d9defe-7bba-447e-8af9-78b2e3a47248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "train_data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3235 entries, 0 to 3234\n",
            "Data columns (total 6 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   id               3235 non-null   float64\n",
            " 1   original_text    3235 non-null   object \n",
            " 2   lang             3231 non-null   object \n",
            " 3   retweet_count    3231 non-null   object \n",
            " 4   original_author  3235 non-null   object \n",
            " 5   sentiment_class  3235 non-null   int64  \n",
            "dtypes: float64(1), int64(1), object(4)\n",
            "memory usage: 151.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfHZgqd_TEnk",
        "colab_type": "code",
        "outputId": "cbb3d9e0-e4db-46c8-e116-650977b42170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original_text</th>\n",
              "      <th>lang</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>original_author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.246628e+18</td>\n",
              "      <td>3. Yeah, I once cooked potatoes when I was 3 y...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>LToddWood</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.245898e+18</td>\n",
              "      <td>Happy Mother's Day to all the mums, step-mums,...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>iiarushii</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.244717e+18</td>\n",
              "      <td>I love the people from the UK, however, when I...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>andreaanderegg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.245730e+18</td>\n",
              "      <td>Happy 81st Birthday Happy Mother’s Day to my m...</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>TheBookTweeters</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.244636e+18</td>\n",
              "      <td>Happy Mothers day to all those wonderful mothe...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>andreaanderegg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  ...  original_author\n",
              "0  1.246628e+18  ...        LToddWood\n",
              "1  1.245898e+18  ...        iiarushii\n",
              "2  1.244717e+18  ...   andreaanderegg\n",
              "3  1.245730e+18  ...  TheBookTweeters\n",
              "4  1.244636e+18  ...   andreaanderegg\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqfmGQCVTEn2",
        "colab_type": "code",
        "outputId": "8754c20b-c060-47d8-d1d5-3431092b83ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "test_data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1387 entries, 0 to 1386\n",
            "Data columns (total 5 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   id               1387 non-null   float64\n",
            " 1   original_text    1387 non-null   object \n",
            " 2   lang             1387 non-null   object \n",
            " 3   retweet_count    1386 non-null   object \n",
            " 4   original_author  1387 non-null   object \n",
            "dtypes: float64(1), object(4)\n",
            "memory usage: 54.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO9Jbr2kvRN2",
        "colab_type": "code",
        "outputId": "d21efa68-519e-44df-9b81-e604f82603ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "train_data.isnull().sum(axis = 0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                 0\n",
              "original_text      0\n",
              "lang               4\n",
              "retweet_count      4\n",
              "original_author    0\n",
              "sentiment_class    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utwjt_kk4igX",
        "colab_type": "code",
        "outputId": "df898880-9fd9-4216-c548-c73a2a5cbc3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "train_data = train_data.fillna(0)\n",
        "train_data.isnull().sum(axis = 0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                 0\n",
              "original_text      0\n",
              "lang               0\n",
              "retweet_count      0\n",
              "original_author    0\n",
              "sentiment_class    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZI_HE7UOEbP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "retweet_replace = ['en',' BLOOD OF PROTECTION AROUND YOU GUYS',' Shop &lt',' have no other means of occasional transportation! Mary.',\" He's told me I don't understand what it means to be a special agent LOL\"]\n",
        "for i in retweet_replace:\n",
        "  train_data['retweet_count'] = train_data['retweet_count'].apply(lambda x: 0 if x == i else x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIwEr5emOICG",
        "colab_type": "code",
        "outputId": "9a64c2dc-18fa-4ae4-8158-bc4ae7628678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "train_data['retweet_count'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0', '1', '3', 0, '2', '12', '4', '0.2255471156', '5', '24',\n",
              "       '0.704111013', '7', '20', '-0.7272841814', '-0.5391119831', '11',\n",
              "       '16', '0.2705365837', '32', '0.6908800807', '6', '0.2356132752',\n",
              "       '-0.5267869213', '-0.4666353157', '-0.8614161431', '9', '8', '17',\n",
              "       '-0.9319417873', '-0.4199361695', '37', '10', '0.1078812656', '27',\n",
              "       '0.9846158924', '33', '13', '15', '118', '59', '-0.8020153269',\n",
              "       '0.8574897643', '14', '-0.3643299313', '0.1005978336', '21', '19',\n",
              "       '0.4005356538', '-0.7229893804', '18', '-0.9278231369',\n",
              "       '-0.1417566007', '0.1869516081', '23', '-0.9386981134', '25',\n",
              "       '-0.3101107397', '0.9930106132', '35', '0.6610057615', '61',\n",
              "       '-0.057256529', '28', '96', '0.3091754197', '45', '0.0375273346',\n",
              "       '0.7006763228'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EIzHU8mTEoL",
        "colab_type": "text"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj2jwIYDTEoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_tweets(tweet):\n",
        "    \n",
        "    # remove URL\n",
        "    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n",
        "    \n",
        "    # Remove usernames\n",
        "    tweet = re.sub(r\"@[^\\s]+[\\s]?\",'',tweet)\n",
        "    \n",
        "    # remove special characters \n",
        "    tweet = re.sub('[^ a-zA-Z0-9]', '', tweet)\n",
        "    \n",
        "    # remove Numbers\n",
        "    tweet = re.sub('[0-9]', '', tweet)\n",
        "    \n",
        "    return tweet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI3BYA_VTEom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data['original_text'] = train_data['original_text'].apply(clean_tweets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBDL_ptATEo2",
        "colab_type": "code",
        "outputId": "cd6464c4-d829-4562-be09-9ce97942b52b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "train_data['original_text'].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Happy MothersDay to all you amazing mothers ou...\n",
              "1    Happy Mothers Day Mum  Im sorry I cant be ther...\n",
              "2    Happy mothers day To all This doing a mothers ...\n",
              "3    Happy mothers day to this beautiful womanroyal...\n",
              "4    Remembering the  most amazing ladies who made ...\n",
              "Name: original_text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D--oeR96TEpH",
        "colab_type": "text"
      },
      "source": [
        "# Tokenization & stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0n6YccdTEpK",
        "colab_type": "code",
        "outputId": "d2a0ae76-af42-45b3-c5ca-3a930ddf13e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Function which directly tokenize the tweet data\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "tt = TweetTokenizer()\n",
        "train_data['original_text'].apply(tt.tokenize)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [Happy, MothersDay, to, all, you, amazing, mot...\n",
              "1       [Happy, Mothers, Day, Mum, Im, sorry, I, cant,...\n",
              "2       [Happy, mothers, day, To, all, This, doing, a,...\n",
              "3       [Happy, mothers, day, to, this, beautiful, wom...\n",
              "4       [Remembering, the, most, amazing, ladies, who,...\n",
              "                              ...                        \n",
              "3230    [To, all, my, sisters, my, sisters, in, law, a...\n",
              "3231    [Happy, Mothers, Day, to, all, the, Mums, Step...\n",
              "3232    [Happy, Mothers, Day, to, the, craziest, woman...\n",
              "3233    [Happy, Mothers, Day, to, my, amazing, wife, W...\n",
              "3234    [Wishing, you, all, a, safe, happy, Mothers, D...\n",
              "Name: original_text, Length: 3235, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSz4cCX6TEpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "ps = PorterStemmer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH-tLYjpTEpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "def stemming(words):\n",
        "    stem_words = []\n",
        "    for w in words:\n",
        "        w = ps.stem(w)\n",
        "        stem_words.append(w)\n",
        "    \n",
        "    return stem_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jpvQJRdTEp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# apply tokenize function\n",
        "train_data['text'] = train_data['original_text'].apply(tokenize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y-kCaCfTEqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# apply steming function\n",
        "train_data['tokenized'] = train_data['text'].apply(stemming)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksEg335bTEqg",
        "colab_type": "code",
        "outputId": "58af8fe5-9512-48ed-f684-92c9355d32a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original_text</th>\n",
              "      <th>lang</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>original_author</th>\n",
              "      <th>sentiment_class</th>\n",
              "      <th>text</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.245025e+18</td>\n",
              "      <td>Happy MothersDay to all you amazing mothers ou...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>BeenXXPired</td>\n",
              "      <td>0</td>\n",
              "      <td>[Happy, MothersDay, to, all, you, amazing, mot...</td>\n",
              "      <td>[happi, mothersday, to, all, you, amaz, mother...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.245759e+18</td>\n",
              "      <td>Happy Mothers Day Mum  Im sorry I cant be ther...</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>FestiveFeeling</td>\n",
              "      <td>0</td>\n",
              "      <td>[Happy, Mothers, Day, Mum, Im, sorry, I, cant,...</td>\n",
              "      <td>[happi, mother, day, mum, Im, sorri, I, cant, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.246087e+18</td>\n",
              "      <td>Happy mothers day To all This doing a mothers ...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>KrisAllenSak</td>\n",
              "      <td>-1</td>\n",
              "      <td>[Happy, mothers, day, To, all, This, doing, a,...</td>\n",
              "      <td>[happi, mother, day, To, all, thi, do, a, moth...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.244803e+18</td>\n",
              "      <td>Happy mothers day to this beautiful womanroyal...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>Queenuchee</td>\n",
              "      <td>0</td>\n",
              "      <td>[Happy, mothers, day, to, this, beautiful, wom...</td>\n",
              "      <td>[happi, mother, day, to, thi, beauti, womanroy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.244876e+18</td>\n",
              "      <td>Remembering the  most amazing ladies who made ...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>brittan17446794</td>\n",
              "      <td>-1</td>\n",
              "      <td>[Remembering, the, most, amazing, ladies, who,...</td>\n",
              "      <td>[rememb, the, most, amaz, ladi, who, made, me,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  ...                                          tokenized\n",
              "0  1.245025e+18  ...  [happi, mothersday, to, all, you, amaz, mother...\n",
              "1  1.245759e+18  ...  [happi, mother, day, mum, Im, sorri, I, cant, ...\n",
              "2  1.246087e+18  ...  [happi, mother, day, To, all, thi, do, a, moth...\n",
              "3  1.244803e+18  ...  [happi, mother, day, to, thi, beauti, womanroy...\n",
              "4  1.244876e+18  ...  [rememb, the, most, amaz, ladi, who, made, me,...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4pd-orKTEqw",
        "colab_type": "text"
      },
      "source": [
        "# Wordlist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPzp12gMTEq0",
        "colab_type": "code",
        "outputId": "028f9744-c756-44e8-bf5a-1d72fc9c2694",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "words = Counter()\n",
        "for idx in train_data.index:\n",
        "    words.update(train_data.loc[idx, \"text\"])\n",
        "\n",
        "words.most_common(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('to', 3673),\n",
              " ('the', 2850),\n",
              " ('Happy', 2738),\n",
              " ('and', 2445),\n",
              " ('Mothers', 2379)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUcDts5uTErG",
        "colab_type": "code",
        "outputId": "4b52ae1c-6385-4177-d267-94c8b937f661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "nltk.download('stopwords')\n",
        "stopwords=nltk.corpus.stopwords.words(\"english\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1obzE6vBTErZ",
        "colab_type": "code",
        "outputId": "ecadb61f-c023-4fa9-e53e-04821de2824f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "whitelist = [\"n't\", \"not\"]\n",
        "for idx, stop_word in enumerate(stopwords):\n",
        "    if stop_word not in whitelist:\n",
        "        del words[stop_word]\n",
        "words.most_common(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Happy', 2738),\n",
              " ('Mothers', 2379),\n",
              " ('Day', 1964),\n",
              " ('day', 1606),\n",
              " ('mothers', 1431)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udsuBFA2TErm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_list(processed_data):\n",
        "    #print(processed_data)\n",
        "    min_occurrences=3 \n",
        "    max_occurences=500 \n",
        "    stopwords=nltk.corpus.stopwords.words(\"english\")\n",
        "    whitelist = [\"n't\",\"not\"]\n",
        "    wordlist = []\n",
        "    \n",
        "    whitelist = whitelist if whitelist is None else whitelist\n",
        "    #print(whitelist)\n",
        "    '''\n",
        "    import os\n",
        "    if os.path.isfile(\"wordlist.csv\"):\n",
        "        word_df = pd.read_csv(\"wordlist.csv\")\n",
        "        word_df = word_df[word_df[\"occurrences\"] > min_occurrences]\n",
        "        wordlist = list(word_df.loc[:, \"word\"])\n",
        "        #return\n",
        "    '''\n",
        "    words = Counter()\n",
        "    for idx in processed_data.index:\n",
        "        words.update(processed_data.loc[idx, \"text\"])\n",
        "\n",
        "    for idx, stop_word in enumerate(stopwords):\n",
        "        if stop_word not in whitelist:\n",
        "            del words[stop_word]\n",
        "    #print(words)\n",
        "\n",
        "    word_df = pd.DataFrame(data={\"word\": [k for k, v in words.most_common() if min_occurrences < v < max_occurences],\n",
        "                                 \"occurrences\": [v for k, v in words.most_common() if min_occurrences < v < max_occurences]},\n",
        "                           columns=[\"word\", \"occurrences\"])\n",
        "    #print(word_df)\n",
        "    word_df.to_csv(\"wordlist.csv\", index_label=\"idx\")\n",
        "    wordlist = [k for k, v in words.most_common() if min_occurrences < v < max_occurences]\n",
        "    #print(wordlist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uADt_xOsTEr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_list(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V1rAHa8TEsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = pd.read_csv(\"wordlist.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2sBwL7dTEsQ",
        "colab_type": "text"
      },
      "source": [
        "# Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UudKa0FLTEsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flYk9AeNTEsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordlist= []\n",
        "if os.path.isfile(\"wordlist.csv\"):\n",
        "    word_df = pd.read_csv(\"wordlist.csv\")\n",
        "    word_df = word_df[word_df[\"occurrences\"] > 3]\n",
        "    wordlist = list(word_df.loc[:, \"word\"])\n",
        "\n",
        "label_column = [\"label\"]\n",
        "columns = label_column + list(map(lambda word: str(word) + '_bow',wordlist))\n",
        "labels = []\n",
        "rows = []\n",
        "for idx in train_data.index:\n",
        "    current_row = []\n",
        "    \n",
        "    # add label\n",
        "    current_label = train_data.loc[idx, \"sentiment_class\"]\n",
        "    labels.append(current_label)\n",
        "    current_row.append(current_label)\n",
        "\n",
        "    # add bag-of-words\n",
        "    tokens = set(train_data.loc[idx, \"text\"])\n",
        "    for _, word in enumerate(wordlist):\n",
        "        current_row.append(1 if word in tokens else 0)\n",
        "\n",
        "    rows.append(current_row)\n",
        "\n",
        "data_model = pd.DataFrame(rows, columns=columns)\n",
        "data_labels = pd.Series(labels)\n",
        "\n",
        "\n",
        "bow = data_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-GJtBu2TEsn",
        "colab_type": "code",
        "outputId": "3fcc4f23-bf6d-43df-8a79-2c2d30a72e14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "bow.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>today_bow</th>\n",
              "      <th>us_bow</th>\n",
              "      <th>We_bow</th>\n",
              "      <th>mother_bow</th>\n",
              "      <th>amazing_bow</th>\n",
              "      <th>not_bow</th>\n",
              "      <th>wonderful_bow</th>\n",
              "      <th>Mum_bow</th>\n",
              "      <th>To_bow</th>\n",
              "      <th>world_bow</th>\n",
              "      <th>one_bow</th>\n",
              "      <th>Mums_bow</th>\n",
              "      <th>know_bow</th>\n",
              "      <th>hope_bow</th>\n",
              "      <th>best_bow</th>\n",
              "      <th>like_bow</th>\n",
              "      <th>safe_bow</th>\n",
              "      <th>beautiful_bow</th>\n",
              "      <th>much_bow</th>\n",
              "      <th>You_bow</th>\n",
              "      <th>wish_bow</th>\n",
              "      <th>lovely_bow</th>\n",
              "      <th>family_bow</th>\n",
              "      <th>time_bow</th>\n",
              "      <th>Love_bow</th>\n",
              "      <th>everyone_bow</th>\n",
              "      <th>DAY_bow</th>\n",
              "      <th>Thank_bow</th>\n",
              "      <th>MOTHERS_bow</th>\n",
              "      <th>Im_bow</th>\n",
              "      <th>always_bow</th>\n",
              "      <th>A_bow</th>\n",
              "      <th>see_bow</th>\n",
              "      <th>every_bow</th>\n",
              "      <th>HAPPY_bow</th>\n",
              "      <th>The_bow</th>\n",
              "      <th>special_bow</th>\n",
              "      <th>happymothersday_bow</th>\n",
              "      <th>women_bow</th>\n",
              "      <th>...</th>\n",
              "      <th>image_bow</th>\n",
              "      <th>Distancing_bow</th>\n",
              "      <th>dream_bow</th>\n",
              "      <th>wrong_bow</th>\n",
              "      <th>Maria_bow</th>\n",
              "      <th>harder_bow</th>\n",
              "      <th>slightly_bow</th>\n",
              "      <th>feels_bow</th>\n",
              "      <th>keepsafe_bow</th>\n",
              "      <th>motherlylove_bow</th>\n",
              "      <th>AMAZING_bow</th>\n",
              "      <th>inthismomentofficial_bow</th>\n",
              "      <th>album_bow</th>\n",
              "      <th>orders_bow</th>\n",
              "      <th>street_bow</th>\n",
              "      <th>cheer_bow</th>\n",
              "      <th>Really_bow</th>\n",
              "      <th>arrived_bow</th>\n",
              "      <th>souls_bow</th>\n",
              "      <th>GOD_bow</th>\n",
              "      <th>RIP_bow</th>\n",
              "      <th>Dinner_bow</th>\n",
              "      <th>healthcare_bow</th>\n",
              "      <th>emotional_bow</th>\n",
              "      <th>pet_bow</th>\n",
              "      <th>potential_bow</th>\n",
              "      <th>Little_bow</th>\n",
              "      <th>vision_bow</th>\n",
              "      <th>FOR_bow</th>\n",
              "      <th>heartbeat_bow</th>\n",
              "      <th>black_bow</th>\n",
              "      <th>Maybe_bow</th>\n",
              "      <th>gem_bow</th>\n",
              "      <th>werent_bow</th>\n",
              "      <th>Markel_bow</th>\n",
              "      <th>countries_bow</th>\n",
              "      <th>calling_bow</th>\n",
              "      <th>Prince_bow</th>\n",
              "      <th>practicing_bow</th>\n",
              "      <th>calls_bow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1819 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  today_bow  us_bow  ...  Prince_bow  practicing_bow  calls_bow\n",
              "0      0          1       1  ...           0               0          0\n",
              "1      0          0       0  ...           0               0          0\n",
              "2     -1          0       0  ...           0               0          0\n",
              "3      0          0       0  ...           0               0          0\n",
              "4     -1          0       0  ...           0               0          0\n",
              "\n",
              "[5 rows x 1819 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-A2rD7zTEs7",
        "colab_type": "text"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1aI6r8ETEs-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "seed = 777\n",
        "random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hNCYLPWTEtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_classifier(X_train, y_train, X_test, y_test, classifier):\n",
        "    log(\"\")\n",
        "    log(\"---------------------------------------------------------\")\n",
        "    log(\"Testing \" + str(type(classifier).__name__))\n",
        "    now = time()\n",
        "    list_of_labels = sorted(list(set(y_train)))\n",
        "    model = classifier.fit(X_train, y_train)\n",
        "    log(\"Learing time {0}s\".format(time() - now))\n",
        "    now = time()\n",
        "    predictions = model.predict(X_test)\n",
        "    log(\"Predicting time {0}s\".format(time() - now))\n",
        "\n",
        "    # Calculate Accuracy, Precision, recall\n",
        "    \n",
        "    precision = precision_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
        "    recall = recall_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    f1 = f1_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
        "    \n",
        "    log(\"=================== Results ===================\")\n",
        "    log(\"            Negative     Neutral     Positive\")\n",
        "    log(\"F1       \" + str(f1))\n",
        "    log(\"Precision\" + str(precision))\n",
        "    log(\"Recall   \" + str(recall))\n",
        "    log(\"Accuracy \" + str(accuracy))\n",
        "    log(\"===============================================\")\n",
        "\n",
        "    return precision, recall, accuracy, f1\n",
        "\n",
        "def log(x):\n",
        "    #can be used to write to log file\n",
        "    print(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MAgKy23TEtV",
        "colab_type": "text"
      },
      "source": [
        "# Experiment 1: BOW + Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfC1_zrZTEtY",
        "colab_type": "code",
        "outputId": "7f2a4af7-6931-4f3d-fff0-90a7a0fde10f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "X_train, X_test, y_train, y_test = train_test_split(bow.iloc[:, 1:], bow['label'], test_size=0.3, random_state=seed)\n",
        "precision, recall, accuracy, f1 = test_classifier(X_train, y_train, X_test, y_test, BernoulliNB())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------------------------\n",
            "Testing BernoulliNB\n",
            "Learing time 0.10297536849975586s\n",
            "Predicting time 0.04215860366821289s\n",
            "=================== Results ===================\n",
            "            Negative     Neutral     Positive\n",
            "F1       [0.1627907  0.6193969  0.20485175]\n",
            "Precision[0.24778761 0.52054795 0.296875  ]\n",
            "Recall   [0.12121212 0.76458753 0.1563786 ]\n",
            "Accuracy 0.4593202883625129\n",
            "===============================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_89XNSxTEtl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cv(classifier, X_train, y_train):\n",
        "    log(\"===============================================\")\n",
        "    classifier_name = str(type(classifier).__name__)\n",
        "    now = time()\n",
        "    log(\"Crossvalidating \" + classifier_name + \"...\")\n",
        "    accuracy = [cross_val_score(classifier, X_train, y_train, cv=8, n_jobs=-1)]\n",
        "    log(\"Crosvalidation completed in {0}s\".format(time() - now))\n",
        "    log(\"Accuracy: \" + str(accuracy[0]))\n",
        "    log(\"Average accuracy: \" + str(np.array(accuracy[0]).mean()))\n",
        "    log(\"===============================================\")\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3h0b9xoTEt3",
        "colab_type": "text"
      },
      "source": [
        "# Add Extra Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf282mhRTEt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv('Train.csv')\n",
        "test_data = pd.read_csv('Test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv-TucJw7B_4",
        "colab_type": "code",
        "outputId": "3a0ffe87-20c3-48c6-86a0-54a8cd1d1f72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "train_data = train_data.fillna(0)\n",
        "train_data.isnull().sum(axis = 0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                 0\n",
              "original_text      0\n",
              "lang               0\n",
              "retweet_count      0\n",
              "original_author    0\n",
              "sentiment_class    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q25ZM5ld7eok",
        "colab_type": "code",
        "outputId": "9334e74c-8e24-47b3-c044-e82af20ab7c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "train_data['retweet_count'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0', '1', '3', 'en', '2', '12', '4', 0, '0.2255471156', '5', '24',\n",
              "       '0.704111013', '7', '20', '-0.7272841814', '-0.5391119831', '11',\n",
              "       '16', ' BLOOD OF PROTECTION AROUND YOU GUYS', '0.2705365837', '32',\n",
              "       '0.6908800807', '6', '0.2356132752', '-0.5267869213',\n",
              "       '-0.4666353157', '-0.8614161431', '9', '8', '17', '-0.9319417873',\n",
              "       '-0.4199361695', '37', '10', '0.1078812656', '27', '0.9846158924',\n",
              "       '33', ' Shop &lt', '13', '15', '118', '59', '-0.8020153269',\n",
              "       '0.8574897643', '14', '-0.3643299313', '0.1005978336', '21', '19',\n",
              "       '0.4005356538', '-0.7229893804', '18', '-0.9278231369',\n",
              "       '-0.1417566007', '0.1869516081', '23', '-0.9386981134', '25',\n",
              "       '-0.3101107397', '0.9930106132', '35',\n",
              "       ' have no other means of occasional transportation! Mary.',\n",
              "       '0.6610057615', '61',\n",
              "       \" He's told me I don't understand what it means to be a special agent LOL\",\n",
              "       '-0.057256529', '28', '96', '0.3091754197', '45', '0.0375273346',\n",
              "       '0.7006763228'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbytUUQ76yLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "retweet_replace = ['en',' BLOOD OF PROTECTION AROUND YOU GUYS',' Shop &lt',' have no other means of occasional transportation! Mary.',\" He's told me I don't understand what it means to be a special agent LOL\"]\n",
        "for i in retweet_replace:\n",
        "  train_data['retweet_count'] = train_data['retweet_count'].apply(lambda x: 0 if x == i else x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY4NgCDFKTwv",
        "colab_type": "code",
        "outputId": "a846c2a1-7400-4f7c-b547-a23c6710d138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "train_data['retweet_count'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0', '1', '3', 0, '2', '12', '4', '0.2255471156', '5', '24',\n",
              "       '0.704111013', '7', '20', '-0.7272841814', '-0.5391119831', '11',\n",
              "       '16', '0.2705365837', '32', '0.6908800807', '6', '0.2356132752',\n",
              "       '-0.5267869213', '-0.4666353157', '-0.8614161431', '9', '8', '17',\n",
              "       '-0.9319417873', '-0.4199361695', '37', '10', '0.1078812656', '27',\n",
              "       '0.9846158924', '33', '13', '15', '118', '59', '-0.8020153269',\n",
              "       '0.8574897643', '14', '-0.3643299313', '0.1005978336', '21', '19',\n",
              "       '0.4005356538', '-0.7229893804', '18', '-0.9278231369',\n",
              "       '-0.1417566007', '0.1869516081', '23', '-0.9386981134', '25',\n",
              "       '-0.3101107397', '0.9930106132', '35', '0.6610057615', '61',\n",
              "       '-0.057256529', '28', '96', '0.3091754197', '45', '0.0375273346',\n",
              "       '0.7006763228'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNGtu5ZoTEuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_extra_feature(df, tweet_column):\n",
        "    \n",
        "    # Print Number of Exclamation\n",
        "    #length_of_excl = (len(re.findall(r'!', string)))\n",
        "    df['number_of_exclamation'] = tweet_column.apply(lambda x: (len(re.findall(r'!', x))))\n",
        "    \n",
        "    # Number of ?\n",
        "    #length_of_questionmark = (len(re.findall(r'?', string)))\n",
        "    df['number_of_questionmark'] = tweet_column.apply(lambda x: (len(re.findall(r'[?]', x))))\n",
        "    \n",
        "    # Number of #\n",
        "    df['number_of_hashtag'] = tweet_column.apply(lambda x: (len(re.findall(r'#', x))))\n",
        "    \n",
        "    # Number of @\n",
        "    df['number_of_mention'] = tweet_column.apply(lambda x: (len(re.findall(r'@', x))))\n",
        "    \n",
        "    # Number of Quotes\n",
        "    df['number_of_quotes'] = tweet_column.apply(lambda x: (len(re.findall(r\"'\", x))))\n",
        "\n",
        "    # Number if underscore\n",
        "    df['number_of_underscore'] = tweet_column.apply(lambda x: (len(re.findall(r'_', x))))\n",
        "    \n",
        "    \n",
        "    #print((txt.split(\" \"), row))\n",
        "    #print(row.split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L42reVPdTEuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pass the train_data into add_extra_feature function\n",
        "add_extra_feature(train_data, train_data[\"original_text\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-swtERG-TEuh",
        "colab_type": "text"
      },
      "source": [
        "# ADD EMOTICONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW1-rUxbTEuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Emoticon Detector\n",
        "\n",
        "class EmoticonDetector:\n",
        "    emoticons = {}\n",
        "\n",
        "    def __init__(self, emoticon_file=\"emoticons.txt\"):\n",
        "        from pathlib import Path\n",
        "        content = Path(emoticon_file).read_text()\n",
        "        positive = True\n",
        "        for line in content.split(\"\\n\"):\n",
        "            if \"positive\" in line.lower():\n",
        "                positive = True\n",
        "                continue\n",
        "            elif \"negative\" in line.lower():\n",
        "                positive = False\n",
        "                continue\n",
        "\n",
        "            self.emoticons[line] = positive\n",
        "\n",
        "    def is_positive(self, emoticon):\n",
        "        if emoticon in self.emoticons:\n",
        "            return self.emoticons[emoticon]\n",
        "        return False\n",
        "\n",
        "    def is_emoticon(self, to_check):\n",
        "        return to_check in self.emoticons"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7qtAlasTEuw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ed = EmoticonDetector()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V3umEaaTEu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_data = train_data.copy()\n",
        "\n",
        "def add_column(column_name, column_content):\n",
        "    processed_data.loc[:, column_name] = pd.Series(column_content, index=processed_data.index)\n",
        "\n",
        "def count_by_lambda(expression, word_array):\n",
        "    return len(list(filter(expression, word_array)))\n",
        "\n",
        "add_column(\"splitted_text\", map(lambda txt: txt.split(\" \"), processed_data[\"original_text\"]))\n",
        "\n",
        "positive_emo = list(\n",
        "    map(lambda txt: count_by_lambda(lambda word: ed.is_emoticon(word) and ed.is_positive(word), txt),\n",
        "        processed_data[\"splitted_text\"]))\n",
        "add_column(\"number_of_positive_emo\", positive_emo)\n",
        "\n",
        "negative_emo = list(map(\n",
        "    lambda txt: count_by_lambda(lambda word: ed.is_emoticon(word) and not ed.is_positive(word), txt),\n",
        "    processed_data[\"splitted_text\"]))\n",
        "\n",
        "add_column(\"number_of_negative_emo\", negative_emo)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rd4Rb_uTEvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data['number_of_positive_emo'] = positive_emo\n",
        "train_data['number_of_negative_emo'] = negative_emo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IB6h79bTEvY",
        "colab_type": "text"
      },
      "source": [
        "# Prepare training data for model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnNTnotkTEvZ",
        "colab_type": "code",
        "outputId": "38b9c927-d92a-401b-9388-fddfce71a3af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original_text</th>\n",
              "      <th>lang</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>original_author</th>\n",
              "      <th>sentiment_class</th>\n",
              "      <th>number_of_exclamation</th>\n",
              "      <th>number_of_questionmark</th>\n",
              "      <th>number_of_hashtag</th>\n",
              "      <th>number_of_mention</th>\n",
              "      <th>number_of_quotes</th>\n",
              "      <th>number_of_underscore</th>\n",
              "      <th>number_of_positive_emo</th>\n",
              "      <th>number_of_negative_emo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.245025e+18</td>\n",
              "      <td>Happy #MothersDay to all you amazing mothers o...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>BeenXXPired</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.245759e+18</td>\n",
              "      <td>Happy Mothers Day Mum - I'm sorry I can't be t...</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>FestiveFeeling</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.246087e+18</td>\n",
              "      <td>Happy mothers day To all This doing a mothers ...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>KrisAllenSak</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.244803e+18</td>\n",
              "      <td>Happy mothers day to this beautiful woman...ro...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>Queenuchee</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.244876e+18</td>\n",
              "      <td>Remembering the 3 most amazing ladies who made...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>brittan17446794</td>\n",
              "      <td>-1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  ... number_of_negative_emo\n",
              "0  1.245025e+18  ...                      0\n",
              "1  1.245759e+18  ...                      0\n",
              "2  1.246087e+18  ...                      0\n",
              "3  1.244803e+18  ...                      0\n",
              "4  1.244876e+18  ...                      0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZlsULC_TEvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# apply the clean tweet function\n",
        "train_data['original_text'] = train_data['original_text'].apply(clean_tweets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNDgkXlITEvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Tokenize & stemming data\n",
        "train_data['text'] = train_data['original_text'].apply(tokenize)\n",
        "train_data['tokenized'] = train_data['text'].apply(stemming)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFlkwCzxUpEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# delete old file first\n",
        "# wordlist\n",
        "word_list(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGjR2lNHTEv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordlist= []\n",
        "if os.path.isfile(\"wordlist.csv\"):\n",
        "    word_df = pd.read_csv(\"wordlist.csv\")\n",
        "    word_df = word_df[word_df[\"occurrences\"] > 3]\n",
        "    wordlist = list(word_df.loc[:, \"word\"])\n",
        "\n",
        "label_column = [\"label\"]\n",
        "columns = label_column + list(map(lambda w: str(w) + \"_bow\",wordlist))\n",
        "labels = []\n",
        "rows = []\n",
        "for idx in train_data.index:\n",
        "    current_row = []\n",
        "        # add label\n",
        "    current_label = train_data.loc[idx, \"sentiment_class\"]\n",
        "    labels.append(current_label)\n",
        "    current_row.append(current_label)\n",
        "\n",
        "    # add bag-of-words\n",
        "    tokens = set(train_data.loc[idx, \"text\"])\n",
        "    for _, word in enumerate(wordlist):\n",
        "        current_row.append(1 if word in tokens else 0)\n",
        "\n",
        "    rows.append(current_row)\n",
        "\n",
        "data_model = pd.DataFrame(rows, columns=columns)\n",
        "data_labels = pd.Series(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jfa_mFGXTEwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dat1 = train_data\n",
        "dat2 = data_model\n",
        "\n",
        "dat1 = dat1.reset_index(drop=True)\n",
        "dat2 = dat2.reset_index(drop=True)\n",
        "\n",
        "data_model = dat1.join(dat2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8gvVSMQTEwn",
        "colab_type": "code",
        "outputId": "f62a43b7-ddea-4672-e68b-c6a1e238e4da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "train_data.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'original_text', 'lang', 'retweet_count', 'original_author',\n",
              "       'sentiment_class', 'number_of_exclamation', 'number_of_questionmark',\n",
              "       'number_of_hashtag', 'number_of_mention', 'number_of_quotes',\n",
              "       'number_of_underscore', 'number_of_positive_emo',\n",
              "       'number_of_negative_emo', 'text', 'tokenized'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIfhMtmkTEwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Drop the columns in data_model\n",
        "data_model = data_model.drop(columns=['id', 'original_text', 'lang', 'original_author',\n",
        "       'sentiment_class', 'text', 'tokenized'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MULBx8cbTExF",
        "colab_type": "code",
        "outputId": "93d75119-aa85-4ea4-8590-3540eb5c1928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "data_model.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['retweet_count', 'number_of_exclamation', 'number_of_questionmark',\n",
              "       'number_of_hashtag', 'number_of_mention', 'number_of_quotes',\n",
              "       'number_of_underscore', 'number_of_positive_emo',\n",
              "       'number_of_negative_emo', 'label',\n",
              "       ...\n",
              "       'black_bow', 'Maybe_bow', 'gem_bow', 'werent_bow', 'Markel_bow',\n",
              "       'countries_bow', 'calling_bow', 'Prince_bow', 'practicing_bow',\n",
              "       'calls_bow'],\n",
              "      dtype='object', length=1828)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByCAy1AYXlsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_model['retweet_count'] = data_model['retweet_count'].astype(float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgwqYUjeTExV",
        "colab_type": "text"
      },
      "source": [
        "# Experiment 2: Added feature + Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJgFC7V5TExY",
        "colab_type": "code",
        "outputId": "e8091182-8c1e-49e5-de63-1d1d2a4621eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_model.drop(columns='label',axis=1),data_model['label'] , test_size=0.3)\n",
        "precision, recall, accuracy, f1 = test_classifier(X_train, y_train, X_test, y_test, RandomForestClassifier(random_state=seed,n_estimators=403,n_jobs=-1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------------------------\n",
            "Testing RandomForestClassifier\n",
            "Learing time 11.087128400802612s\n",
            "Predicting time 0.31198644638061523s\n",
            "=================== Results ===================\n",
            "            Negative     Neutral     Positive\n",
            "F1       [0.125      0.68069666 0.07971014]\n",
            "Precision[0.27272727 0.54982415 0.21153846]\n",
            "Recall   [0.08108108 0.89333333 0.04910714]\n",
            "Accuracy 0.5128733264675592\n",
            "===============================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKp3befvTExp",
        "colab_type": "code",
        "outputId": "ad0af816-4d3d-4ddd-a31f-5126fd797cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "rf_acc = cv(RandomForestClassifier(n_estimators=403,n_jobs=-1, random_state=seed),data_model.drop(columns='label',axis=1), data_model['label'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===============================================\n",
            "Crossvalidating RandomForestClassifier...\n",
            "Crosvalidation completed in 132.67884182929993s\n",
            "Accuracy: [0.47901235 0.51358025 0.49382716 0.50742574 0.48019802 0.51485149\n",
            " 0.4950495  0.4950495 ]\n",
            "Average accuracy: 0.4973742513140203\n",
            "===============================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4wG2RlVTExy",
        "colab_type": "text"
      },
      "source": [
        "# Experiment 3: Added Feature + XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC-zMm_yTEx1",
        "colab_type": "code",
        "outputId": "485175c5-da55-426d-ed11-67825566332d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!pip install xgboost\n",
        "from xgboost import XGBClassifier as XGBoostClassifier"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqxSkR4mTEyB",
        "colab_type": "code",
        "outputId": "dcd5a97f-03af-4edc-c5c4-af290940cb65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data_model.drop(columns='label',axis=1),data_model['label'] , test_size=0.3)\n",
        "precision, recall, accuracy, f1 = test_classifier(X_train, y_train, X_test, y_test, XGBoostClassifier(seed=seed))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------------------------\n",
            "Testing XGBClassifier\n",
            "Learing time 25.302754402160645s\n",
            "Predicting time 0.07223892211914062s\n",
            "=================== Results ===================\n",
            "            Negative     Neutral     Positive\n",
            "F1       [0.02542373 0.69135802 0.03225806]\n",
            "Precision[0.2        0.53903743 0.19047619]\n",
            "Recall   [0.01357466 0.96367113 0.01762115]\n",
            "Accuracy 0.5262615859938208\n",
            "===============================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvRpAZWlTEyK",
        "colab_type": "code",
        "outputId": "0d65acd5-1214-44b7-9f03-6bd92296af87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "xgb_acc = cv(XGBoostClassifier(seed=seed),data_model.drop(columns='label',axis=1), data_model['label'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===============================================\n",
            "Crossvalidating XGBClassifier...\n",
            "Crosvalidation completed in 186.26300859451294s\n",
            "Accuracy: [0.52592593 0.52839506 0.51358025 0.51485149 0.51732673 0.51732673\n",
            " 0.52227723 0.51732673]\n",
            "Average accuracy: 0.5196262681823738\n",
            "===============================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYrouP0sTEyQ",
        "colab_type": "text"
      },
      "source": [
        "# Experiment 4: Added Feature + Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmOcoFXPTEyR",
        "colab_type": "code",
        "outputId": "0c0b64d1-bb5c-47a0-975f-cbf9f3dcd35e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data_model.drop(columns='label',axis=1),data_model['label'] , test_size=0.3)\n",
        "precision, recall, accuracy, f1 = test_classifier(X_train, y_train, X_test, y_test, BernoulliNB())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------------------------\n",
            "Testing BernoulliNB\n",
            "Learing time 0.16372966766357422s\n",
            "Predicting time 0.05246543884277344s\n",
            "=================== Results ===================\n",
            "            Negative     Neutral     Positive\n",
            "F1       [0.11363636 0.60576923 0.10526316]\n",
            "Precision[0.17391304 0.5046729  0.1682243 ]\n",
            "Recall   [0.08438819 0.75751503 0.07659574]\n",
            "Accuracy 0.42842430484037075\n",
            "===============================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYGd91-bTEyg",
        "colab_type": "code",
        "outputId": "f114abe1-abb4-4677-b336-baf7ec8c9c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "nb_acc = cv(BernoulliNB(), data_model.drop(columns='label',axis=1), data_model['label'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===============================================\n",
            "Crossvalidating BernoulliNB...\n",
            "Crosvalidation completed in 1.4047167301177979s\n",
            "Accuracy: [0.45925926 0.44691358 0.43209877 0.47772277 0.42079208 0.44554455\n",
            " 0.41584158 0.43564356]\n",
            "Average accuracy: 0.4417270199242146\n",
            "===============================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G4iplaZV-ML",
        "colab_type": "text"
      },
      "source": [
        "# Finding best parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3FSWgPCTEyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def report(results, n_top=3):\n",
        "    for i in range(1, n_top + 1):\n",
        "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
        "        for candidate in candidates:\n",
        "            log(\"Model with rank: {0}\".format(i))\n",
        "            log(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
        "                results['mean_test_score'][candidate],\n",
        "                results['std_test_score'][candidate]))\n",
        "            log(\"Parameters: {0}\".format(results['params'][candidate]))\n",
        "            log(\"\")\n",
        "\n",
        "def best_fit(X_train, y_train, n_iter=5):\n",
        "    \n",
        "    parameters = {\n",
        "        \"n_estimators\":[103,201, 403],\n",
        "        \"max_depth\":[3,10,15, 30],\n",
        "        \"objective\":[\"multi:softmax\",\"binary:logistic\"],\n",
        "        \"learning_rate\":[0.05, 0.1, 0.15, 0.3]\n",
        "    }\n",
        "\n",
        "    rand_search = RandomizedSearchCV(XGBoostClassifier(seed=seed),param_distributions=parameters,\n",
        "                                     n_iter=n_iter,scoring=\"accuracy\",\n",
        "                                     n_jobs=-1,cv=8)\n",
        "\n",
        "    import time as ttt\n",
        "    now = time()\n",
        "    log(ttt.ctime())\n",
        "    rand_search.fit(X_train, y_train)\n",
        "    report(rand_search.cv_results_, 10)\n",
        "    log(ttt.ctime())\n",
        "    log(\"Search took: \" + str(time() - now))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUOi4myVTEzF",
        "colab_type": "code",
        "outputId": "29bb3174-ea2e-437d-dd6b-e80052b5b023",
        "colab": {}
      },
      "source": [
        "best_fit(data_model.drop(columns='label',axis=1), data_model['label'], n_iter=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun  9 19:21:50 2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5hplUzdWLUM",
        "colab_type": "text"
      },
      "source": [
        "# Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i6euHWaWOfo",
        "colab_type": "code",
        "outputId": "a244db66-a73d-4783-c6bc-4a36a519f4e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original_text</th>\n",
              "      <th>lang</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>original_author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.246628e+18</td>\n",
              "      <td>3. Yeah, I once cooked potatoes when I was 3 y...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>LToddWood</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.245898e+18</td>\n",
              "      <td>Happy Mother's Day to all the mums, step-mums,...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>iiarushii</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.244717e+18</td>\n",
              "      <td>I love the people from the UK, however, when I...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>andreaanderegg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.245730e+18</td>\n",
              "      <td>Happy 81st Birthday Happy Mother’s Day to my m...</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>TheBookTweeters</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.244636e+18</td>\n",
              "      <td>Happy Mothers day to all those wonderful mothe...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>andreaanderegg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  ...  original_author\n",
              "0  1.246628e+18  ...        LToddWood\n",
              "1  1.245898e+18  ...        iiarushii\n",
              "2  1.244717e+18  ...   andreaanderegg\n",
              "3  1.245730e+18  ...  TheBookTweeters\n",
              "4  1.244636e+18  ...   andreaanderegg\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOCuBxQBWWaM",
        "colab_type": "code",
        "outputId": "c3f06e57-92b2-4d1f-a444-7666ba6476c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_data.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'original_text', 'lang', 'retweet_count', 'original_author'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrPu7XgaWXXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove the tweets which contains Not available\n",
        "test_data = test_data[test_data['original_text'] != \"Not Available\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hWDshWYLy6W",
        "colab_type": "code",
        "outputId": "ff436202-ef47-4398-d31b-b306b928d9b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "test_data = test_data.fillna(0)\n",
        "test_data.isnull().sum(axis = 0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                 0\n",
              "original_text      0\n",
              "lang               0\n",
              "retweet_count      0\n",
              "original_author    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUoqwckPMEZy",
        "colab_type": "code",
        "outputId": "9a5b4dc9-886f-420e-ba3e-d3bb7cbdc2db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "test_data['retweet_count'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0', '1', '2', 'en', '-0.9676057189',\n",
              "       'encouraging- thanks. more2come', '5', '13', '3', '17', '31', '14',\n",
              "       '6', '0.5309002891', '26', '4', '44', '58', '-0.1277872725',\n",
              "       '0.4963592171', 0, '16', '-0.8606548851', '15', '11', '29', '7',\n",
              "       '8', '0.0182429262', '19', '0.6782208946', '0.5248572384',\n",
              "       '-0.9417957712', '40', '35', ' Shop &lt', '-0.7073840905', '10',\n",
              "       ' Day//Gift for Moms//Personalized Shirt', '47', '33',\n",
              "       '0.4802438451'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKGx5BvCMQ1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "retweet_replace = ['en','encouraging- thanks. more2come',' Shop &lt',' Day//Gift for Moms//Personalized Shirt']\n",
        "for i in retweet_replace:\n",
        "  test_data['retweet_count'] = test_data['retweet_count'].apply(lambda x: 0 if x == i else x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfAeliAeMquH",
        "colab_type": "code",
        "outputId": "94869c1c-c877-4df8-ee8e-3a635916580a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "test_data['retweet_count'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0', '1', '2', 0, '-0.9676057189', '5', '13', '3', '17', '31',\n",
              "       '14', '6', '0.5309002891', '26', '4', '44', '58', '-0.1277872725',\n",
              "       '0.4963592171', '16', '-0.8606548851', '15', '11', '29', '7', '8',\n",
              "       '0.0182429262', '19', '0.6782208946', '0.5248572384',\n",
              "       '-0.9417957712', '40', '35', '-0.7073840905', '10', '47', '33',\n",
              "       '0.4802438451'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqRhro7Vq813",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_data = test_data.copy()\n",
        "\n",
        "def add_column(column_name, column_content):\n",
        "    processed_data.loc[:, column_name] = pd.Series(column_content, index=processed_data.index)\n",
        "\n",
        "def count_by_lambda(expression, word_array):\n",
        "    return len(list(filter(expression, word_array)))\n",
        "\n",
        "add_column(\"splitted_text\", map(lambda txt: txt.split(\" \"), processed_data[\"original_text\"]))\n",
        "\n",
        "positive_emo = list(\n",
        "    map(lambda txt: count_by_lambda(lambda word: ed.is_emoticon(word) and ed.is_positive(word), txt),\n",
        "        processed_data[\"splitted_text\"]))\n",
        "add_column(\"number_of_positive_emo\", positive_emo)\n",
        "\n",
        "negative_emo = list(map(\n",
        "    lambda txt: count_by_lambda(lambda word: ed.is_emoticon(word) and not ed.is_positive(word), txt),\n",
        "    processed_data[\"splitted_text\"]))\n",
        "\n",
        "add_column(\"number_of_negative_emo\", negative_emo)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnRthHBPWa6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop null values\n",
        "test_data = test_data.dropna() \n",
        "\n",
        "# add extra features\n",
        "add_extra_feature(test_data, test_data['original_text'])\n",
        "\n",
        "# add emoticon\n",
        "test_data['number_of_positive_emo'] = positive_emo\n",
        "test_data['number_of_negative_emo'] = negative_emo\n",
        "\n",
        "# Clean tweets\n",
        "test_data['original_text'] = test_data['original_text'].apply(clean_tweets)\n",
        "\n",
        "## Tokenize data\n",
        "test_data['text'] = test_data['original_text'].apply(tokenize)\n",
        "test_data['tokenized'] = test_data['text'].apply(stemming)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIHsAv5_Wrbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# wordlist\n",
        "#word_list(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeK8E7GdWw76",
        "colab_type": "code",
        "outputId": "9a564935-f277-4562-888b-953b86f9645e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "## BAG OF WORDS\n",
        "wordlist= []\n",
        "if os.path.isfile(\"wordlist.csv\"):\n",
        "    word_df = pd.read_csv(\"wordlist.csv\")\n",
        "    word_df = word_df[word_df[\"occurrences\"] > 3]\n",
        "    wordlist = list(word_df.loc[:, \"word\"])\n",
        "\n",
        "label_column = [\"label\"]\n",
        "columns = label_column + list(map(lambda w: str(w) + \"_bow\",wordlist))\n",
        "labels = []\n",
        "rows = []\n",
        "for idx in test_data.index:\n",
        "    current_row = []\n",
        "    current_row.append('retweet_count')\n",
        "        # add label\n",
        "    #current_label = test_data.loc[idx, \"original_text\"]\n",
        "    #labels.append(current_label)\n",
        "    #current_row.append(current_label)\n",
        "\n",
        "    # add bag-of-words\n",
        "    tokens = set(test_data.loc[idx, \"text\"])\n",
        "    for _, word in enumerate(wordlist):\n",
        "        current_row.append(1 if word in tokens else 0)\n",
        "\n",
        "    rows.append(current_row)\n",
        "\n",
        "test_data_model = pd.DataFrame(rows, columns=columns)\n",
        "data_labels = pd.Series(labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKZpQVIuWzjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dat1 = test_data\n",
        "dat2 = test_data_model\n",
        "\n",
        "dat1 = dat1.reset_index(drop=True)\n",
        "dat2 = dat2.reset_index(drop=True)\n",
        "\n",
        "test_data_model = dat1.join(dat2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJw0W9R5W2LL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_model = pd.DataFrame()\n",
        "test_model['id'] = test_data_model['id']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZvcyhW7Y-2a",
        "colab_type": "code",
        "outputId": "a39b7795-a08e-4a25-a5d3-9a21d7679cb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "test_data_model.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'original_text', 'lang', 'retweet_count', 'original_author',\n",
              "       'number_of_exclamation', 'number_of_questionmark', 'number_of_hashtag',\n",
              "       'number_of_mention', 'number_of_quotes',\n",
              "       ...\n",
              "       'black_bow', 'Maybe_bow', 'gem_bow', 'werent_bow', 'Markel_bow',\n",
              "       'countries_bow', 'calling_bow', 'Prince_bow', 'practicing_bow',\n",
              "       'calls_bow'],\n",
              "      dtype='object', length=1834)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHvQBR0nZz5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_model['retweet_count'] = test_data_model['retweet_count'].astype(float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1blD104kW4ge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_model = test_data_model.drop(columns=['id', 'original_text', 'lang', 'original_author'\n",
        ", 'text', 'tokenized', 'label'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGutG1AKu2gV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_model.to_csv(\"test_data_model.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piV4vY4r09YU",
        "colab_type": "code",
        "outputId": "a1bb834a-e7c1-4035-c193-371447c2e9b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "RF = RandomForestClassifier(random_state=seed,n_estimators=403,max_depth=10)\n",
        "RF.fit(data_model.drop(columns='label',axis=1),data_model['label'])\n",
        "RF_predictions = RF.predict(test_data_model)\n",
        "RF_results = pd.DataFrame([],columns=[\"id\",\"sentiment_class\"])\n",
        "RF_results[\"id\"] = test_model[\"id\"].astype(\"int64\")\n",
        "RF_results[\"sentiment_class\"] = RF_predictions\n",
        "RF_results.to_csv(\"results_RF.csv\",index=False)\n",
        "RF_results[\"sentiment_class\"].unique()\n",
        "RF_results[\"sentiment_class\"].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1386\n",
              "1       1\n",
              "Name: sentiment_class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1Yoyh7bt4R4",
        "colab_type": "code",
        "outputId": "df534ef4-8003-4c96-904a-9e3a59d8394b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "BN = BernoulliNB()\n",
        "BN.fit(data_model.drop(columns='label',axis=1),data_model['label'])\n",
        "BN_predictions = BN.predict(test_data_model)\n",
        "BN_results = pd.DataFrame([],columns=[\"id\",\"sentiment_class\"])\n",
        "BN_results[\"id\"] = test_model[\"id\"].astype(\"int64\")\n",
        "BN_results[\"sentiment_class\"] = BN_predictions\n",
        "BN_results.to_csv(\"results_BN.csv\",index=False)\n",
        "BN_results[\"sentiment_class\"].unique()\n",
        "BN_results[\"sentiment_class\"].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    1062\n",
              " 1     169\n",
              "-1     156\n",
              "Name: sentiment_class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXd8dOUgwLzm",
        "colab_type": "code",
        "outputId": "e6a6de8f-1d9a-46af-e93f-ba290af3705c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "GB = XGBoostClassifier(seed=seed)\n",
        "GB.fit(data_model.drop(columns='label',axis=1),data_model['label'])\n",
        "GB_predictions = GB.predict(test_data_model)\n",
        "GB_results = pd.DataFrame([],columns=[\"id\",\"sentiment_class\"])\n",
        "GB_results[\"id\"] = test_model[\"id\"].astype(\"int64\")\n",
        "GB_results[\"sentiment_class\"] = GB_predictions\n",
        "GB_results.to_csv(\"results_GB.csv\",index=False)\n",
        "GB_results[\"sentiment_class\"].unique()\n",
        "GB_results[\"sentiment_class\"].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    1362\n",
              "-1      17\n",
              " 1       8\n",
              "Name: sentiment_class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMbXWYT_4uqf",
        "colab_type": "code",
        "outputId": "7d309873-21ce-4c24-9399-890d91e72156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "from nltk.classify import MaxentClassifier\n",
        "ME = MaxentClassifier.train(test_data_model, max_iter=30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-118-93b70c7e01e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMaxentClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxentClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/classify/maxent.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cls, train_toks, algorithm, trace, encoding, labels, gaussian_prior_sigma, **cutoffs)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'iis'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             return train_maxent_classifier_with_iis(\n\u001b[0;32m--> 293\u001b[0;31m                 train_toks, trace, encoding, labels, **cutoffs)\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gis'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             return train_maxent_classifier_with_gis(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/classify/maxent.py\u001b[0m in \u001b[0;36mtrain_maxent_classifier_with_iis\u001b[0;34m(train_toks, trace, encoding, labels, **cutoffs)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[0;31m# Construct an encoding from the training data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m         \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinaryMaxentFeatureEncoding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_toks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m     \u001b[0;31m# Count how many times each feature occurs in the training data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/classify/maxent.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cls, train_toks, count_cutoff, labels, **options)\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# maps (fname, fval) -> count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_toks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unexpected label %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CdoIMA1626j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}