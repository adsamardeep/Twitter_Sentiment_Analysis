{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Amar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import pandas as pd\n",
    "#from emoticons import EmoticonDetector\n",
    "import re as regex\n",
    "import numpy as np\n",
    "#import plotly\n",
    "#from plotly import graph_objs\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#plotly.offline.init_notebook_mode()\n",
    "\n",
    "import seaborn as sns\n",
    "#import plotly\n",
    "#import cufflinks as cf\n",
    "import re\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('Train.csv')\n",
    "test_data = pd.read_csv('Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>original_author</th>\n",
       "      <th>sentiment_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.245025e+18</td>\n",
       "      <td>Happy #MothersDay to all you amazing mothers o...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>BeenXXPired</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.245759e+18</td>\n",
       "      <td>Happy Mothers Day Mum - I'm sorry I can't be t...</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>FestiveFeeling</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.246087e+18</td>\n",
       "      <td>Happy mothers day To all This doing a mothers ...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>KrisAllenSak</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.244803e+18</td>\n",
       "      <td>Happy mothers day to this beautiful woman...ro...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>Queenuchee</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.244876e+18</td>\n",
       "      <td>Remembering the 3 most amazing ladies who made...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>brittan17446794</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                      original_text lang  \\\n",
       "0  1.245025e+18  Happy #MothersDay to all you amazing mothers o...   en   \n",
       "1  1.245759e+18  Happy Mothers Day Mum - I'm sorry I can't be t...   en   \n",
       "2  1.246087e+18  Happy mothers day To all This doing a mothers ...   en   \n",
       "3  1.244803e+18  Happy mothers day to this beautiful woman...ro...   en   \n",
       "4  1.244876e+18  Remembering the 3 most amazing ladies who made...   en   \n",
       "\n",
       "  retweet_count  original_author  sentiment_class  \n",
       "0             0      BeenXXPired                0  \n",
       "1             1   FestiveFeeling                0  \n",
       "2             0     KrisAllenSak               -1  \n",
       "3             0       Queenuchee                0  \n",
       "4             0  brittan17446794               -1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3235 entries, 0 to 3234\n",
      "Data columns (total 6 columns):\n",
      "id                 3235 non-null float64\n",
      "original_text      3235 non-null object\n",
      "lang               3231 non-null object\n",
      "retweet_count      3231 non-null object\n",
      "original_author    3235 non-null object\n",
      "sentiment_class    3235 non-null int64\n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 151.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>original_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.246628e+18</td>\n",
       "      <td>3. Yeah, I once cooked potatoes when I was 3 y...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>LToddWood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.245898e+18</td>\n",
       "      <td>Happy Mother's Day to all the mums, step-mums,...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>iiarushii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.244717e+18</td>\n",
       "      <td>I love the people from the UK, however, when I...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>andreaanderegg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.245730e+18</td>\n",
       "      <td>Happy 81st Birthday Happy Mother’s Day to my m...</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>TheBookTweeters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.244636e+18</td>\n",
       "      <td>Happy Mothers day to all those wonderful mothe...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>andreaanderegg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                      original_text lang  \\\n",
       "0  1.246628e+18  3. Yeah, I once cooked potatoes when I was 3 y...   en   \n",
       "1  1.245898e+18  Happy Mother's Day to all the mums, step-mums,...   en   \n",
       "2  1.244717e+18  I love the people from the UK, however, when I...   en   \n",
       "3  1.245730e+18  Happy 81st Birthday Happy Mother’s Day to my m...   en   \n",
       "4  1.244636e+18  Happy Mothers day to all those wonderful mothe...   en   \n",
       "\n",
       "  retweet_count  original_author  \n",
       "0             0        LToddWood  \n",
       "1             0        iiarushii  \n",
       "2             0   andreaanderegg  \n",
       "3             1  TheBookTweeters  \n",
       "4             0   andreaanderegg  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1387 entries, 0 to 1386\n",
      "Data columns (total 5 columns):\n",
      "id                 1387 non-null float64\n",
      "original_text      1387 non-null object\n",
      "lang               1387 non-null object\n",
      "retweet_count      1386 non-null object\n",
      "original_author    1387 non-null object\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 54.3+ KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweet):\n",
    "    \n",
    "    # remove URL\n",
    "    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "    \n",
    "    # Remove usernames\n",
    "    tweet = re.sub(r\"@[^\\s]+[\\s]?\",'',tweet)\n",
    "    \n",
    "    # remove special characters \n",
    "    tweet = re.sub('[^ a-zA-Z0-9]', '', tweet)\n",
    "    \n",
    "    # remove Numbers\n",
    "    tweet = re.sub('[0-9]', '', tweet)\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['original_text'] = train_data['original_text'].apply(clean_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Happy MothersDay to all you amazing mothers ou...\n",
       "1    Happy Mothers Day Mum  Im sorry I cant be ther...\n",
       "2    Happy mothers day To all This doing a mothers ...\n",
       "3    Happy mothers day to this beautiful womanroyal...\n",
       "4    Remembering the  most amazing ladies who made ...\n",
       "Name: original_text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['original_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization & stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Happy, MothersDay, to, all, you, amazing, mot...\n",
       "1       [Happy, Mothers, Day, Mum, Im, sorry, I, cant,...\n",
       "2       [Happy, mothers, day, To, all, This, doing, a,...\n",
       "3       [Happy, mothers, day, to, this, beautiful, wom...\n",
       "4       [Remembering, the, most, amazing, ladies, who,...\n",
       "                              ...                        \n",
       "3230    [To, all, my, sisters, my, sisters, in, law, a...\n",
       "3231    [Happy, Mothers, Day, to, all, the, Mums, Step...\n",
       "3232    [Happy, Mothers, Day, to, the, craziest, woman...\n",
       "3233    [Happy, Mothers, Day, to, my, amazing, wife, W...\n",
       "3234    [Wishing, you, all, a, safe, happy, Mothers, D...\n",
       "Name: original_text, Length: 3235, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function which directly tokenize the tweet data\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tt = TweetTokenizer()\n",
    "train_data['original_text'].apply(tt.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def stemming(words):\n",
    "    stem_words = []\n",
    "    for w in words:\n",
    "        w = ps.stem(w)\n",
    "        stem_words.append(w)\n",
    "    \n",
    "    return stem_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply tokenize function\n",
    "train_data['text'] = train_data['original_text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply steming function\n",
    "train_data['tokenized'] = train_data['text'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>original_author</th>\n",
       "      <th>sentiment_class</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.245025e+18</td>\n",
       "      <td>Happy MothersDay to all you amazing mothers ou...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>BeenXXPired</td>\n",
       "      <td>0</td>\n",
       "      <td>[Happy, MothersDay, to, all, you, amazing, mot...</td>\n",
       "      <td>[happi, mothersday, to, all, you, amaz, mother...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.245759e+18</td>\n",
       "      <td>Happy Mothers Day Mum  Im sorry I cant be ther...</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>FestiveFeeling</td>\n",
       "      <td>0</td>\n",
       "      <td>[Happy, Mothers, Day, Mum, Im, sorry, I, cant,...</td>\n",
       "      <td>[happi, mother, day, mum, Im, sorri, I, cant, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.246087e+18</td>\n",
       "      <td>Happy mothers day To all This doing a mothers ...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>KrisAllenSak</td>\n",
       "      <td>-1</td>\n",
       "      <td>[Happy, mothers, day, To, all, This, doing, a,...</td>\n",
       "      <td>[happi, mother, day, To, all, thi, do, a, moth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.244803e+18</td>\n",
       "      <td>Happy mothers day to this beautiful womanroyal...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>Queenuchee</td>\n",
       "      <td>0</td>\n",
       "      <td>[Happy, mothers, day, to, this, beautiful, wom...</td>\n",
       "      <td>[happi, mother, day, to, thi, beauti, womanroy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.244876e+18</td>\n",
       "      <td>Remembering the  most amazing ladies who made ...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>brittan17446794</td>\n",
       "      <td>-1</td>\n",
       "      <td>[Remembering, the, most, amazing, ladies, who,...</td>\n",
       "      <td>[rememb, the, most, amaz, ladi, who, made, me,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                      original_text lang  \\\n",
       "0  1.245025e+18  Happy MothersDay to all you amazing mothers ou...   en   \n",
       "1  1.245759e+18  Happy Mothers Day Mum  Im sorry I cant be ther...   en   \n",
       "2  1.246087e+18  Happy mothers day To all This doing a mothers ...   en   \n",
       "3  1.244803e+18  Happy mothers day to this beautiful womanroyal...   en   \n",
       "4  1.244876e+18  Remembering the  most amazing ladies who made ...   en   \n",
       "\n",
       "  retweet_count  original_author  sentiment_class  \\\n",
       "0             0      BeenXXPired                0   \n",
       "1             1   FestiveFeeling                0   \n",
       "2             0     KrisAllenSak               -1   \n",
       "3             0       Queenuchee                0   \n",
       "4             0  brittan17446794               -1   \n",
       "\n",
       "                                                text  \\\n",
       "0  [Happy, MothersDay, to, all, you, amazing, mot...   \n",
       "1  [Happy, Mothers, Day, Mum, Im, sorry, I, cant,...   \n",
       "2  [Happy, mothers, day, To, all, This, doing, a,...   \n",
       "3  [Happy, mothers, day, to, this, beautiful, wom...   \n",
       "4  [Remembering, the, most, amazing, ladies, who,...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [happi, mothersday, to, all, you, amaz, mother...  \n",
       "1  [happi, mother, day, mum, Im, sorri, I, cant, ...  \n",
       "2  [happi, mother, day, To, all, thi, do, a, moth...  \n",
       "3  [happi, mother, day, to, thi, beauti, womanroy...  \n",
       "4  [rememb, the, most, amaz, ladi, who, made, me,...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 3673),\n",
       " ('the', 2850),\n",
       " ('Happy', 2738),\n",
       " ('and', 2445),\n",
       " ('Mothers', 2379)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = Counter()\n",
    "for idx in train_data.index:\n",
    "    words.update(train_data.loc[idx, \"text\"])\n",
    "\n",
    "words.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Amar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords=nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Happy', 2738),\n",
       " ('Mothers', 2379),\n",
       " ('Day', 1964),\n",
       " ('day', 1606),\n",
       " ('mothers', 1431)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whitelist = [\"n't\", \"not\"]\n",
    "for idx, stop_word in enumerate(stopwords):\n",
    "    if stop_word not in whitelist:\n",
    "        del words[stop_word]\n",
    "words.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_list(processed_data):\n",
    "    #print(processed_data)\n",
    "    min_occurrences=3 \n",
    "    max_occurences=500 \n",
    "    stopwords=nltk.corpus.stopwords.words(\"english\")\n",
    "    whitelist = [\"n't\",\"not\"]\n",
    "    wordlist = []\n",
    "    \n",
    "    whitelist = whitelist if whitelist is None else whitelist\n",
    "    #print(whitelist)\n",
    "    '''\n",
    "    import os\n",
    "    if os.path.isfile(\"wordlist.csv\"):\n",
    "        word_df = pd.read_csv(\"wordlist.csv\")\n",
    "        word_df = word_df[word_df[\"occurrences\"] > min_occurrences]\n",
    "        wordlist = list(word_df.loc[:, \"word\"])\n",
    "        #return\n",
    "    '''\n",
    "    words = Counter()\n",
    "    for idx in processed_data.index:\n",
    "        words.update(processed_data.loc[idx, \"text\"])\n",
    "\n",
    "    for idx, stop_word in enumerate(stopwords):\n",
    "        if stop_word not in whitelist:\n",
    "            del words[stop_word]\n",
    "    #print(words)\n",
    "\n",
    "    word_df = pd.DataFrame(data={\"word\": [k for k, v in words.most_common() if min_occurrences < v < max_occurences],\n",
    "                                 \"occurrences\": [v for k, v in words.most_common() if min_occurrences < v < max_occurences]},\n",
    "                           columns=[\"word\", \"occurrences\"])\n",
    "    #print(word_df)\n",
    "    word_df.to_csv(\"wordlist.csv\", index_label=\"idx\")\n",
    "    wordlist = [k for k, v in words.most_common() if min_occurrences < v < max_occurences]\n",
    "    #print(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.read_csv(\"wordlist.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist= []\n",
    "if os.path.isfile(\"wordlist.csv\"):\n",
    "    word_df = pd.read_csv(\"wordlist.csv\")\n",
    "    word_df = word_df[word_df[\"occurrences\"] > 3]\n",
    "    wordlist = list(word_df.loc[:, \"word\"])\n",
    "\n",
    "label_column = [\"label\"]\n",
    "columns = label_column + list(map(lambda word: str(word) + '_bow',wordlist))\n",
    "labels = []\n",
    "rows = []\n",
    "for idx in train_data.index:\n",
    "    current_row = []\n",
    "    \n",
    "    # add label\n",
    "    current_label = train_data.loc[idx, \"sentiment_class\"]\n",
    "    labels.append(current_label)\n",
    "    current_row.append(current_label)\n",
    "\n",
    "    # add bag-of-words\n",
    "    tokens = set(train_data.loc[idx, \"text\"])\n",
    "    for _, word in enumerate(wordlist):\n",
    "        current_row.append(1 if word in tokens else 0)\n",
    "\n",
    "    rows.append(current_row)\n",
    "\n",
    "data_model = pd.DataFrame(rows, columns=columns)\n",
    "data_labels = pd.Series(labels)\n",
    "\n",
    "\n",
    "bow = data_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>today_bow</th>\n",
       "      <th>us_bow</th>\n",
       "      <th>We_bow</th>\n",
       "      <th>mother_bow</th>\n",
       "      <th>amazing_bow</th>\n",
       "      <th>not_bow</th>\n",
       "      <th>wonderful_bow</th>\n",
       "      <th>Mum_bow</th>\n",
       "      <th>To_bow</th>\n",
       "      <th>...</th>\n",
       "      <th>black_bow</th>\n",
       "      <th>Maybe_bow</th>\n",
       "      <th>gem_bow</th>\n",
       "      <th>werent_bow</th>\n",
       "      <th>Markel_bow</th>\n",
       "      <th>countries_bow</th>\n",
       "      <th>calling_bow</th>\n",
       "      <th>Prince_bow</th>\n",
       "      <th>practicing_bow</th>\n",
       "      <th>calls_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1819 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  today_bow  us_bow  We_bow  mother_bow  amazing_bow  not_bow  \\\n",
       "0      0          1       1       0           0            1        1   \n",
       "1      0          0       0       0           0            0        0   \n",
       "2     -1          0       0       0           0            0        0   \n",
       "3      0          0       0       0           0            0        0   \n",
       "4     -1          0       0       0           0            1        0   \n",
       "\n",
       "   wonderful_bow  Mum_bow  To_bow  ...  black_bow  Maybe_bow  gem_bow  \\\n",
       "0              0        0       0  ...          0          0        0   \n",
       "1              0        1       0  ...          0          0        0   \n",
       "2              0        0       1  ...          0          0        0   \n",
       "3              0        0       0  ...          0          0        0   \n",
       "4              0        0       0  ...          0          0        0   \n",
       "\n",
       "   werent_bow  Markel_bow  countries_bow  calling_bow  Prince_bow  \\\n",
       "0           0           0              0            0           0   \n",
       "1           0           0              0            0           0   \n",
       "2           0           0              0            0           0   \n",
       "3           0           0              0            0           0   \n",
       "4           0           0              0            0           0   \n",
       "\n",
       "   practicing_bow  calls_bow  \n",
       "0               0          0  \n",
       "1               0          0  \n",
       "2               0          0  \n",
       "3               0          0  \n",
       "4               0          0  \n",
       "\n",
       "[5 rows x 1819 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed = 777\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(X_train, y_train, X_test, y_test, classifier):\n",
    "    log(\"\")\n",
    "    log(\"---------------------------------------------------------\")\n",
    "    log(\"Testing \" + str(type(classifier).__name__))\n",
    "    now = time()\n",
    "    list_of_labels = sorted(list(set(y_train)))\n",
    "    model = classifier.fit(X_train, y_train)\n",
    "    log(\"Learing time {0}s\".format(time() - now))\n",
    "    now = time()\n",
    "    predictions = model.predict(X_test)\n",
    "    log(\"Predicting time {0}s\".format(time() - now))\n",
    "\n",
    "    # Calculate Accuracy, Precision, recall\n",
    "    \n",
    "    precision = precision_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    recall = recall_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    \n",
    "    log(\"=================== Results ===================\")\n",
    "    log(\"            Negative     Neutral     Positive\")\n",
    "    log(\"F1       \" + str(f1))\n",
    "    log(\"Precision\" + str(precision))\n",
    "    log(\"Recall   \" + str(recall))\n",
    "    log(\"Accuracy \" + str(accuracy))\n",
    "    log(\"===============================================\")\n",
    "\n",
    "    return precision, recall, accuracy, f1\n",
    "\n",
    "def log(x):\n",
    "    #can be used to write to log file\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: BOW + Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------\n",
      "Testing BernoulliNB\n",
      "Learing time 0.48799610137939453s\n",
      "Predicting time 0.14699816703796387s\n",
      "=================== Results ===================\n",
      "            Negative     Neutral     Positive\n",
      "F1       [0.1627907  0.6193969  0.20485175]\n",
      "Precision[0.24778761 0.52054795 0.296875  ]\n",
      "Recall   [0.12121212 0.76458753 0.1563786 ]\n",
      "Accuracy 0.4593202883625129\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow.iloc[:, 1:], bow['label'], test_size=0.3, random_state=seed)\n",
    "precision, recall, accuracy, f1 = test_classifier(X_train, y_train, X_test, y_test, BernoulliNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(classifier, X_train, y_train):\n",
    "    log(\"===============================================\")\n",
    "    classifier_name = str(type(classifier).__name__)\n",
    "    now = time()\n",
    "    log(\"Crossvalidating \" + classifier_name + \"...\")\n",
    "    accuracy = [cross_val_score(classifier, X_train, y_train, cv=8, n_jobs=-1)]\n",
    "    log(\"Crosvalidation completed in {0}s\".format(time() - now))\n",
    "    log(\"Accuracy: \" + str(accuracy[0]))\n",
    "    log(\"Average accuracy: \" + str(np.array(accuracy[0]).mean()))\n",
    "    log(\"===============================================\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Extra Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('Train.csv')\n",
    "test_data = pd.read_csv('Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_extra_feature(df, tweet_column):\n",
    "    \n",
    "    # Print Number of Exclamation\n",
    "    #length_of_excl = (len(re.findall(r'!', string)))\n",
    "    df['number_of_exclamation'] = tweet_column.apply(lambda x: (len(re.findall(r'!', x))))\n",
    "    \n",
    "    # Number of ?\n",
    "    #length_of_questionmark = (len(re.findall(r'?', string)))\n",
    "    df['number_of_questionmark'] = tweet_column.apply(lambda x: (len(re.findall(r'[?]', x))))\n",
    "    \n",
    "    # Number of #\n",
    "    df['number_of_hashtag'] = tweet_column.apply(lambda x: (len(re.findall(r'#', x))))\n",
    "    \n",
    "    # Number of @\n",
    "    df['number_of_mention'] = tweet_column.apply(lambda x: (len(re.findall(r'@', x))))\n",
    "    \n",
    "    # Number of Quotes\n",
    "    df['number_of_quotes'] = tweet_column.apply(lambda x: (len(re.findall(r\"'\", x))))\n",
    "\n",
    "    # Number if underscore\n",
    "    df['number_of_underscore'] = tweet_column.apply(lambda x: (len(re.findall(r'_', x))))\n",
    "    \n",
    "    \n",
    "    #print((txt.split(\" \"), row))\n",
    "    #print(row.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the train_data into add_extra_feature function\n",
    "add_extra_feature(train_data, train_data[\"original_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD EMOTICONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Emoticon Detector\n",
    "\n",
    "class EmoticonDetector:\n",
    "    emoticons = {}\n",
    "\n",
    "    def __init__(self, emoticon_file=\"emoticons.txt\"):\n",
    "        from pathlib import Path\n",
    "        content = Path(emoticon_file).read_text()\n",
    "        positive = True\n",
    "        for line in content.split(\"\\n\"):\n",
    "            if \"positive\" in line.lower():\n",
    "                positive = True\n",
    "                continue\n",
    "            elif \"negative\" in line.lower():\n",
    "                positive = False\n",
    "                continue\n",
    "\n",
    "            self.emoticons[line] = positive\n",
    "\n",
    "    def is_positive(self, emoticon):\n",
    "        if emoticon in self.emoticons:\n",
    "            return self.emoticons[emoticon]\n",
    "        return False\n",
    "\n",
    "    def is_emoticon(self, to_check):\n",
    "        return to_check in self.emoticons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed = EmoticonDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = train_data.copy()\n",
    "\n",
    "def add_column(column_name, column_content):\n",
    "    processed_data.loc[:, column_name] = pd.Series(column_content, index=processed_data.index)\n",
    "\n",
    "def count_by_lambda(expression, word_array):\n",
    "    return len(list(filter(expression, word_array)))\n",
    "\n",
    "add_column(\"splitted_text\", map(lambda txt: txt.split(\" \"), processed_data[\"original_text\"]))\n",
    "\n",
    "positive_emo = list(\n",
    "    map(lambda txt: count_by_lambda(lambda word: ed.is_emoticon(word) and ed.is_positive(word), txt),\n",
    "        processed_data[\"splitted_text\"]))\n",
    "add_column(\"number_of_positive_emo\", positive_emo)\n",
    "\n",
    "negative_emo = list(map(\n",
    "    lambda txt: count_by_lambda(lambda word: ed.is_emoticon(word) and not ed.is_positive(word), txt),\n",
    "    processed_data[\"splitted_text\"]))\n",
    "\n",
    "add_column(\"number_of_negative_emo\", negative_emo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['number_of_positive_emo'] = positive_emo\n",
    "train_data['number_of_negative_emo'] = negative_emo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>original_author</th>\n",
       "      <th>sentiment_class</th>\n",
       "      <th>number_of_exclamation</th>\n",
       "      <th>number_of_questionmark</th>\n",
       "      <th>number_of_hashtag</th>\n",
       "      <th>number_of_mention</th>\n",
       "      <th>number_of_quotes</th>\n",
       "      <th>number_of_underscore</th>\n",
       "      <th>number_of_positive_emo</th>\n",
       "      <th>number_of_negative_emo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.245025e+18</td>\n",
       "      <td>Happy #MothersDay to all you amazing mothers o...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>BeenXXPired</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.245759e+18</td>\n",
       "      <td>Happy Mothers Day Mum - I'm sorry I can't be t...</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>FestiveFeeling</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.246087e+18</td>\n",
       "      <td>Happy mothers day To all This doing a mothers ...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>KrisAllenSak</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.244803e+18</td>\n",
       "      <td>Happy mothers day to this beautiful woman...ro...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>Queenuchee</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.244876e+18</td>\n",
       "      <td>Remembering the 3 most amazing ladies who made...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>brittan17446794</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                      original_text lang  \\\n",
       "0  1.245025e+18  Happy #MothersDay to all you amazing mothers o...   en   \n",
       "1  1.245759e+18  Happy Mothers Day Mum - I'm sorry I can't be t...   en   \n",
       "2  1.246087e+18  Happy mothers day To all This doing a mothers ...   en   \n",
       "3  1.244803e+18  Happy mothers day to this beautiful woman...ro...   en   \n",
       "4  1.244876e+18  Remembering the 3 most amazing ladies who made...   en   \n",
       "\n",
       "  retweet_count  original_author  sentiment_class  number_of_exclamation  \\\n",
       "0             0      BeenXXPired                0                      1   \n",
       "1             1   FestiveFeeling                0                      1   \n",
       "2             0     KrisAllenSak               -1                      0   \n",
       "3             0       Queenuchee                0                      0   \n",
       "4             0  brittan17446794               -1                      3   \n",
       "\n",
       "   number_of_questionmark  number_of_hashtag  number_of_mention  \\\n",
       "0                       0                  2                  0   \n",
       "1                       0                  0                  0   \n",
       "2                       0                  1                  0   \n",
       "3                       0                  2                  0   \n",
       "4                       0                  0                  0   \n",
       "\n",
       "   number_of_quotes  number_of_underscore  number_of_positive_emo  \\\n",
       "0                 2                     0                       0   \n",
       "1                 4                     0                       0   \n",
       "2                 0                     0                       0   \n",
       "3                 0                     0                       0   \n",
       "4                 0                     0                       0   \n",
       "\n",
       "   number_of_negative_emo  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the clean tweet function\n",
    "train_data['original_text'] = train_data['original_text'].apply(clean_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenize & stemming data\n",
    "train_data['text'] = train_data['original_text'].apply(tokenize)\n",
    "train_data['tokenized'] = train_data['text'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist= []\n",
    "if os.path.isfile(\"wordlist.csv\"):\n",
    "    word_df = pd.read_csv(\"wordlist.csv\")\n",
    "    word_df = word_df[word_df[\"occurrences\"] > 3]\n",
    "    wordlist = list(word_df.loc[:, \"word\"])\n",
    "\n",
    "label_column = [\"label\"]\n",
    "columns = label_column + list(map(lambda w: str(w) + \"_bow\",wordlist))\n",
    "labels = []\n",
    "rows = []\n",
    "for idx in train_data.index:\n",
    "    current_row = []\n",
    "        # add label\n",
    "    current_label = train_data.loc[idx, \"sentiment_class\"]\n",
    "    labels.append(current_label)\n",
    "    current_row.append(current_label)\n",
    "\n",
    "    # add bag-of-words\n",
    "    tokens = set(train_data.loc[idx, \"text\"])\n",
    "    for _, word in enumerate(wordlist):\n",
    "        current_row.append(1 if word in tokens else 0)\n",
    "\n",
    "    rows.append(current_row)\n",
    "\n",
    "data_model = pd.DataFrame(rows, columns=columns)\n",
    "data_labels = pd.Series(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat1 = train_data\n",
    "dat2 = data_model\n",
    "\n",
    "dat1 = dat1.reset_index(drop=True)\n",
    "dat2 = dat2.reset_index(drop=True)\n",
    "\n",
    "data_model = dat1.join(dat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'original_text', 'lang', 'retweet_count', 'original_author',\n",
       "       'sentiment_class', 'number_of_exclamation', 'number_of_questionmark',\n",
       "       'number_of_hashtag', 'number_of_mention', 'number_of_quotes',\n",
       "       'number_of_underscore', 'number_of_positive_emo',\n",
       "       'number_of_negative_emo', 'text', 'tokenized'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop the columns in data_model\n",
    "data_model = data_model.drop(columns=['id', 'original_text', 'lang', 'retweet_count', 'original_author',\n",
    "       'sentiment_class', 'text', 'tokenized'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number_of_exclamation', 'number_of_questionmark', 'number_of_hashtag',\n",
       "       'number_of_mention', 'number_of_quotes', 'number_of_underscore',\n",
       "       'number_of_positive_emo', 'number_of_negative_emo', 'label',\n",
       "       'today_bow',\n",
       "       ...\n",
       "       'black_bow', 'Maybe_bow', 'gem_bow', 'werent_bow', 'Markel_bow',\n",
       "       'countries_bow', 'calling_bow', 'Prince_bow', 'practicing_bow',\n",
       "       'calls_bow'],\n",
       "      dtype='object', length=1827)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: Added feature + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------\n",
      "Testing RandomForestClassifier\n",
      "Learing time 17.766369581222534s\n",
      "Predicting time 0.534226655960083s\n",
      "=================== Results ===================\n",
      "            Negative     Neutral     Positive\n",
      "F1       [0.14634146 0.68181818 0.11683849]\n",
      "Precision[0.328125   0.55357143 0.25373134]\n",
      "Recall   [0.0941704  0.88740458 0.07589286]\n",
      "Accuracy 0.518022657054583\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_model.drop(columns='label',axis=1),data_model['label'] , test_size=0.3)\n",
    "precision, recall, accuracy, f1 = test_classifier(X_train, y_train, X_test, y_test, RandomForestClassifier(random_state=seed,n_estimators=403,n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "Crossvalidating RandomForestClassifier...\n",
      "Crosvalidation completed in 199.65104413032532s\n",
      "Accuracy: [0.48275862 0.52592593 0.47654321 0.49382716 0.48641975 0.51861042\n",
      " 0.51116625 0.49875931]\n",
      "Average accuracy: 0.49925133127765686\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "rf_acc = cv(RandomForestClassifier(n_estimators=403,n_jobs=-1, random_state=seed),data_model.drop(columns='label',axis=1), data_model['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3: Added Feature + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading https://files.pythonhosted.org/packages/29/31/580e1a2cd683fa219b272bd4f52540c987a5f4be5d28ed506a87c551667f/xgboost-1.1.1-py3-none-win_amd64.whl (54.4MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\amar\\anaconda3\\lib\\site-packages (from xgboost) (1.16.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\amar\\anaconda3\\lib\\site-packages (from xgboost) (1.3.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "from xgboost import XGBClassifier as XGBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------\n",
      "Testing XGBClassifier\n",
      "Learing time 108.92083263397217s\n",
      "Predicting time 0.4709954261779785s\n",
      "=================== Results ===================\n",
      "            Negative     Neutral     Positive\n",
      "F1       [0.15238095 0.63741339 0.12804878]\n",
      "Precision[0.26373626 0.53626943 0.19444444]\n",
      "Recall   [0.10714286 0.78557875 0.09545455]\n",
      "Accuracy 0.4727085478887745\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_model.drop(columns='label',axis=1),data_model['label'] , test_size=0.3)\n",
    "precision, recall, accuracy, f1 = test_classifier(X_train, y_train, X_test, y_test, XGBoostClassifier(seed=seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "Crossvalidating XGBClassifier...\n",
      "Crosvalidation completed in 954.9081835746765s\n",
      "Accuracy: [0.48029557 0.50617284 0.47407407 0.4962963  0.49135802 0.46898263\n",
      " 0.49131514 0.46650124]\n",
      "Average accuracy: 0.4843744760643166\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "xgb_acc = cv(XGBoostClassifier(seed=seed),data_model.drop(columns='label',axis=1), data_model['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4: Added Feature + Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------\n",
      "Testing BernoulliNB\n",
      "Learing time 0.5520036220550537s\n",
      "Predicting time 0.15999817848205566s\n",
      "=================== Results ===================\n",
      "            Negative     Neutral     Positive\n",
      "F1       [0.16976127 0.58959538 0.17514124]\n",
      "Precision[0.22535211 0.5        0.26956522]\n",
      "Recall   [0.13617021 0.71830986 0.12970711]\n",
      "Accuracy 0.4325437693099897\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_model.drop(columns='label',axis=1),data_model['label'] , test_size=0.3)\n",
    "precision, recall, accuracy, f1 = test_classifier(X_train, y_train, X_test, y_test, BernoulliNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "Crossvalidating BernoulliNB...\n",
      "Crosvalidation completed in 13.766727209091187s\n",
      "Accuracy: [0.45320197 0.44691358 0.43209877 0.47407407 0.41728395 0.44416873\n",
      " 0.42183623 0.43424318]\n",
      "Average accuracy: 0.44047755997144206\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "nb_acc = cv(BernoulliNB(), data_model.drop(columns='label',axis=1), data_model['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            log(\"Model with rank: {0}\".format(i))\n",
    "            log(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                results['mean_test_score'][candidate],\n",
    "                results['std_test_score'][candidate]))\n",
    "            log(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            log(\"\")\n",
    "\n",
    "def best_fit(X_train, y_train, n_iter=5):\n",
    "    \n",
    "    parameters = {\n",
    "        \"n_estimators\":[103,201, 403],\n",
    "        \"max_depth\":[3,10,15, 30],\n",
    "        \"objective\":[\"multi:softmax\",\"binary:logistic\"],\n",
    "        \"learning_rate\":[0.05, 0.1, 0.15, 0.3]\n",
    "    }\n",
    "\n",
    "    rand_search = RandomizedSearchCV(XGBoostClassifier(seed=seed),param_distributions=parameters,\n",
    "                                     n_iter=n_iter,scoring=\"accuracy\",\n",
    "                                     n_jobs=-1,cv=8)\n",
    "\n",
    "    import time as ttt\n",
    "    now = time()\n",
    "    log(ttt.ctime())\n",
    "    rand_search.fit(X_train, y_train)\n",
    "    report(rand_search.cv_results_, 10)\n",
    "    log(ttt.ctime())\n",
    "    log(\"Search took: \" + str(time() - now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun  9 19:21:50 2020\n"
     ]
    }
   ],
   "source": [
    "best_fit(data_model.drop(columns='label',axis=1), data_model['label'], n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
